{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mailbox import mbox\n",
    "import pandas as pd\n",
    "\n",
    "def store_content(message, body=None):\n",
    "    if not body:\n",
    "        body = message.get_payload(decode=True)\n",
    "    if len(message):\n",
    "        contents = {\n",
    "            \"subject\": message[\"subject\"] or \"\",\n",
    "            \"body\": body,\n",
    "            \"from\": message[\"from\"],\n",
    "            \"to\": message[\"to\"],\n",
    "            \"date\": message[\"date\"],\n",
    "            \"labels\": message[\"X-Gmail-Labels\"],\n",
    "            \"epilogue\": message.epilogue,\n",
    "        }\n",
    "        return df.append(contents, ignore_index=True)\n",
    "\n",
    "# Create empty DataFrame with relevant columns\n",
    "df = pd.DataFrame(\n",
    "    columns=(\"subject\", \"body\", \"from\", \"to\", \"date\", \"labels\", \"epilogue\")\n",
    ")\n",
    "\n",
    "# Import downloaded mbox file\n",
    "box = mbox(\"Takeout/Mail/AllmailIncludingSpamandTrash.mbox\")\n",
    "\n",
    "fails = []\n",
    "for message in box:\n",
    "    try:\n",
    "        if message.get_content_type() == 'text/plain':\n",
    "            df = store_content(message)\n",
    "        elif message.is_multipart():\n",
    "            # Grab any plaintext from multipart messages\n",
    "            for part in message.get_payload():\n",
    "                if part.get_content_type() == 'text/plain':\n",
    "                    df = store_content(message, part.get_payload(decode=True))\n",
    "                    break\n",
    "    except:\n",
    "        fails.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 4041), ('off', 3303), ('for', 3283), ('on', 3053), ('the', 3046), ('new', 2983), ('your', 2569), ('&', 2560), ('and', 2422), ('-', 2370)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "subject_word_bag = df.subject.apply(lambda t: str(t).lower() + \" \").sum()\n",
    "\n",
    "print(Counter(subject_word_bag.split()).most_common()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('new', 2983), ('free', 1142), ('save', 1001), ('|', 867), ('sale', 834), ('today', 740), ('20%', 732), ('online', 712), ('extra', 644), ('commented', 639)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = [str(word) for word in stopwords.words('english')] + ['re:', 'fwd:', '_', '&', '-', '+']\n",
    "subject_words = [word for word in subject_word_bag.split() if str(word).lower() not in stops]\n",
    "print(Counter(subject_words).most_common()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('new', 'jobs'), 0.0032635591520096302)\n",
      "(('free', 'shipping'), 0.002808800909516485)\n",
      "(('free', 'shipping.'), 0.002287166454891995)\n",
      "(('bar', 'room'), 0.0022136026215475156)\n",
      "(('[the', 'bar'), 0.002193539757908112)\n",
      "(('room', 'heroes]'), 0.002193539757908112)\n",
      "(('stores', 'online'), 0.002066474954858557)\n",
      "(('15', 'new'), 0.0016050290911522771)\n",
      "(('extra', '30%'), 0.0014779642881027218)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n"
     ]
    }
   ],
   "source": [
    "from nltk import collocations\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "bigram_finder = collocations.BigramCollocationFinder.from_words(subject_words)\n",
    "\n",
    "# Filter to top 20 results; otherwise this will take a LONG time\n",
    "bigram_finder.apply_freq_filter(20)\n",
    "for bigram in bigram_finder.score_ngrams(bigram_measures.raw_freq)[:10]:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n",
      "(('photo', 'you.'), 0.0014177756971845115)\n"
     ]
    }
   ],
   "source": [
    "from nltk import collocations\n",
    "trigram_measures = collocations.TrigramAssocMeasures()\n",
    "trigram_finder = collocations.TrigramCollocationFinder.from_words(subject_words)\n",
    "\n",
    "# Filter to top 20 results; otherwise this will take a LONG time\n",
    "trigram_finder.apply_freq_filter(20)\n",
    "for trigram in trigram_finder.score_ngrams(trigram_measures.raw_freq)[:10]:\n",
    "    print(trigram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
